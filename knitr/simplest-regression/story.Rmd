---
title: "Simplest regression (for the Bayes in Stan book)"
author: "Andrew Gelman"
date: "27 Jun 2018"
output:
  html_document:
    theme: readable
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
options(digits = 2)

library(ggplot2)

library(gridExtra)

library(knitr)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
knitr::opts_chunk$set(comment = "")

print_file <- function(file) {
  cat(paste(readLines(file), "\n", sep=""), sep="")
}

extract_one_draw <- function(stanfit, chain = 1, iter = 1) {
  x <- get_inits(stanfit, iter = iter)
  x[[chain]]
}
```

We begin our R session by loading in Stan, setting it to run in parallel and to save compiled Stan programs in the working directory:
```{r}
library("rstan")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```
Then we write the program to simulate fake data:
```{r}
print_file("fake-data.stan")
```
To run this, we need to specify the sample size $N$, the regression coefficients $a$ and $b$, the residual standard deviation $\sigma$, and the vector of predictors $x$, which we then put in a list:
```{r}
N <- 100
data <- list(N=N, a=2, b=3, sigma=5, x=runif(N, 0, 10))
```
We then run the Stan model and create the fake data:
```{r, warning=FALSE, results=FALSE}
fake_data <- stan("fake-data.stan", chains=1, iter=1, algorithm="Fixed_param", data=data)
```
We only needed one chain and one iteration as we are just simulating one fake dataset (in this case, a vector $y$ of length 100).  Also, just to know:  the first time you run this on your computer, you'll have to wait 15 seconds or so for the Stan model to compile.  After that, it will save the compiled code in your home directory.

Here is the Stan program to fit the model:
```{r}
print_file("model.stan")
```
To run this program from R, we must first put together the data:

```{r, results=FALSE}
data$y <- extract_one_draw(fake_data)$y
fit <- stan("model.stan", data=data)

```
We can summarize the fitted model:
```{r}
print(fit)

```
Now we go through the output:

* The first few lines summarize the Stan run, with the name of the file, the number of chains and iterations.  In this case, Stan ran the default 4 chains with 1000 warmup iterations followed by 1000 post-warmup iterations, yielding 4000 post-warmup simulation draws in total.

* The left column of the table has the names of parameters, transformed parameters, and generated quantities produced by model.stan.  In this case, the parameters are a, b, and sigma; the only transformed parameter is lp__ (the log-posterior density or target function created by the Stan model); and there are no generated quantities.

* The next column of the table shows the mean (average) of the 4000 draws for each quantity.

* The next column shows the Monte Carlo standard error, which is an estimate of the uncertainty in the mean.

* The next column shows the standard deviation of the draws for each quantity.  As the number of simulation draws increases, mean should approach the posterior mean, se_mean should go to zero, and sd should approach the posterior standard deviation.  For most purposes we can ignore se_mean.

* The next several columns give quantiles of the simulations.

* The next columns gives the effective sample size and $\widehat{R}$. Typically we want $\widehat{R}$ to be less then 1.1 for each quantity in the table.

In the above output, $\widehat{R}$ is less then 1.1 for all quantities, so the chains seem to have mixed well, and we use the results to summarize the posterior distribution.  We can compare the posterior inferences to the true parameter values (here, $a=2$, $b=3$, and $\sigma=5$).  These true values are roughly within the range of uncertainty of the inferences.

